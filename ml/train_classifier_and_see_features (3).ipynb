{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3n-jZH2zbefl"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# 1. Import Libraries\n",
        "# ================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9knIaAKIboGU",
        "outputId": "cbad71ad-add9-4656-c41c-0b9495c16ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "None\n",
            "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
            "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
            "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
            "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
            "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
            "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
            "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
            "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
            "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
            "\n",
            "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
            "count  768.000000                768.000000  768.000000  768.000000  \n",
            "mean    31.992578                  0.471876   33.240885    0.348958  \n",
            "std      7.884160                  0.331329   11.760232    0.476951  \n",
            "min      0.000000                  0.078000   21.000000    0.000000  \n",
            "25%     27.300000                  0.243750   24.000000    0.000000  \n",
            "50%     32.000000                  0.372500   29.000000    0.000000  \n",
            "75%     36.600000                  0.626250   41.000000    1.000000  \n",
            "max     67.100000                  2.420000   81.000000    1.000000  \n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# 2. Load Dataset\n",
        "# ================================================\n",
        "df = pd.read_csv(\"/content/diabetes.csv\")   # <-- change filename\n",
        "\n",
        "print(df.head())   # preview\n",
        "print(df.info())   # datatypes\n",
        "print(df.describe())  # quick stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y8U2mI1dbujQ"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# 3. Identify Features and Target\n",
        "# ================================================\n",
        "target_col = \"Outcome\"  # <-- change to your target\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZPIrN7XWb0w6"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# 4. Train-Test Split\n",
        "# ================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y if y.nunique() > 1 and y.value_counts().min() >= 2 else None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I91eAz5Rb5Q7"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# 5. Preprocessing Pipelines\n",
        "# ================================================\n",
        "# Separate numerical and categorical columns\n",
        "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "\n",
        "# Numerical pipeline\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical pipeline\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "# Combine both\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_pipeline, num_features),\n",
        "        (\"cat\", cat_pipeline, cat_features)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqXU4H-wvVQ8",
        "outputId": "816abf16-0339-4294-973d-f61ce88154e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ColumnTransformer(transformers=[('num',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(strategy='median')),\n",
            "                                                 ('scaler', StandardScaler())]),\n",
            "                                 Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
            "       'BMI', 'DiabetesPedigreeFunction', 'Age'],\n",
            "      dtype='object')),\n",
            "                                ('cat',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(strategy='most_frequent')),\n",
            "                                                 ('onehot',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
            "                                 Index([], dtype='object'))])\n"
          ]
        }
      ],
      "source": [
        "print(preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Hfe3wIb-FB",
        "outputId": "faa6f6f7-4df4-4444-a2a6-e6a46c9a2add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SelectKBest(k=20)\n",
            "Selected features:\n",
            "['num__Pregnancies' 'num__Glucose' 'num__BloodPressure'\n",
            " 'num__SkinThickness' 'num__Insulin' 'num__BMI'\n",
            " 'num__DiabetesPedigreeFunction' 'num__Age']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=8. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# 6. Add Feature Selection\n",
        "# ================================================\n",
        "# Select top K features using ANOVA F-test\n",
        "feature_selector = SelectKBest(score_func=f_classif, k=20)  # <-- adjust \"k\"\n",
        "print(feature_selector)\n",
        "\n",
        "# Fit the feature selector on the processed training data\n",
        "# This requires X_train_processed to be generated by running the cell below this one first.\n",
        "X_train_processed = preprocessor.fit_transform(X_train, y_train)\n",
        "feature_selector.fit(X_train_processed, y_train)\n",
        "\n",
        "all_features = preprocessor.get_feature_names_out()\n",
        "selected_features = all_features[feature_selector.get_support()]\n",
        "\n",
        "print(\"Selected features:\")\n",
        "print(selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8LBFWS5ca7G",
        "outputId": "6fb83661-4cf9-4596-dd4d-63fb9de0106f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=8. All the features will be returned.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=8. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.7337662337662337\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.75      0.79       100\n",
            "           1       0.60      0.70      0.65        54\n",
            "\n",
            "    accuracy                           0.73       154\n",
            "   macro avg       0.71      0.73      0.72       154\n",
            "weighted avg       0.75      0.73      0.74       154\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Random Forest\n",
            "Accuracy: 0.7597402597402597\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       100\n",
            "           1       0.68      0.59      0.63        54\n",
            "\n",
            "    accuracy                           0.76       154\n",
            "   macro avg       0.74      0.72      0.73       154\n",
            "weighted avg       0.75      0.76      0.76       154\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=8. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Gradient Boosting\n",
            "Accuracy: 0.7532467532467533\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.84      0.82       100\n",
            "           1       0.67      0.59      0.63        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: SVM\n",
            "Accuracy: 0.7532467532467533\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.81       100\n",
            "           1       0.66      0.61      0.63        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: KNN\n",
            "Accuracy: 0.7012987012987013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.80      0.78       100\n",
            "           1       0.58      0.52      0.55        54\n",
            "\n",
            "    accuracy                           0.70       154\n",
            "   macro avg       0.67      0.66      0.66       154\n",
            "weighted avg       0.69      0.70      0.70       154\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=8. All the features will be returned.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=8. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# 7. Candidate Models\n",
        "# ================================================\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "best_pipelines = {}\n",
        "\n",
        "for name, clf in models.items():\n",
        "    pipe = Pipeline(steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"feature_select\", feature_selector),   # <-- feature selection\n",
        "        (\"classifier\", clf)\n",
        "    ])\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = acc\n",
        "    best_pipelines[name] = pipe\n",
        "\n",
        "    print(f\"Model: {name}\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNxXbaZ5chAs",
        "outputId": "b82e9c5f-4d16-4003-9de0-2f230fd5864c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model: Random Forest with Accuracy: 0.7597402597402597\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# 8. Pick Best Model\n",
        "# ================================================\n",
        "best_model_name = max(results, key=results.get)\n",
        "best_pipe = best_pipelines[best_model_name]\n",
        "\n",
        "print(\"Best Model:\", best_model_name, \"with Accuracy:\", results[best_model_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btgmFCsMcpWa",
        "outputId": "83f62362-af75-416d-e15c-69474e9cf3e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=10 is greater than n_features=8. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Params: {'classifier__max_depth': 10, 'classifier__n_estimators': 100, 'feature_select__k': 10}\n",
            "Best CV Score: 0.7768892443022791\n",
            "Test Accuracy: 0.7532467532467533\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# 9. Hyperparameter Tuning on Best Model\n",
        "# ================================================\n",
        "if best_model_name == \"Random Forest\":\n",
        "    param_grid = {\n",
        "        \"classifier__n_estimators\": [100, 200, 300],\n",
        "        \"classifier__max_depth\": [None, 5, 10, 20],\n",
        "        \"feature_select__k\": [5, 10, 15]  # also tune feature selection\n",
        "    }\n",
        "elif best_model_name == \"Logistic Regression\":\n",
        "    param_grid = {\n",
        "        \"classifier__C\": [0.01, 0.1, 1, 10],\n",
        "        \"feature_select__k\": [5, 10, 15]\n",
        "    }\n",
        "elif best_model_name == \"SVM\":\n",
        "    param_grid = {\n",
        "        \"classifier__C\": [0.1, 1, 10],\n",
        "        \"classifier__kernel\": [\"linear\", \"rbf\"],\n",
        "        \"feature_select__k\": [5, 10, 15]\n",
        "    }\n",
        "elif best_model_name == \"Gradient Boosting\":\n",
        "    param_grid = {\n",
        "        \"classifier__n_estimators\": [100, 200],\n",
        "        \"classifier__learning_rate\": [0.01, 0.1, 0.2],\n",
        "        \"feature_select__k\": [5, 10, 15]\n",
        "    }\n",
        "elif best_model_name == \"KNN\":\n",
        "    param_grid = {\n",
        "        \"classifier__n_neighbors\": [3, 5, 7, 9],\n",
        "        \"feature_select__k\": [5, 10, 15]\n",
        "    }\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=best_pipe,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Best CV Score:\", grid.best_score_)\n",
        "print(\"Test Accuracy:\", grid.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSTSo9lDcuoJ",
        "outputId": "d59f225e-3ca3-449d-faaa-3a2938a6eb36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/best_pipeline.joblib']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(best_pipe, \"/content/best_pipeline.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
